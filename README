==================================================================

Python implementation of a simple Locally Sensitive Hashing

==================================================================

This is a python implementation of a locally sensitive hashing scheme

that makes use of the Goemans-Williamson rounding technique for approximating

MAXCUT. A locally sensitive hashing scheme maps "close" strings to the same 

bucket. The notion of closeness depends on the way the data is mapped to

vectors (for instance the characteristic vector if it is a text, or the 

frequency vector). The Goemans-Williamson rounding technique samples a n-variate

Gaussian x (n being the dimension of the data) and rounds the data vector v to 1

if <v,x> >= 0 and to 0 otherwise. Here we map an n-bit vector to a log^2(n) vector

with the probability of collision being:

	(1-a/\pi)^{log^2(n)} 

where a is the angle between the two vectors. This is approximately exponentially

small in n if the data is "not too similar".

The generate-example.py generates a file (by default named data) with random vectors.

The hash.py uses this hashing scheme to hash it to a file of your choosing. It also 

outputs the number of collisions that were observed on the data. A sample data file is

included in the repository. 

Reference: http://www.cs.princeton.edu/courses/archive/spring04/cos598B/bib/CharikarEstim.pdf 
