===================================================================

Python 3 implementation of a simple Locality Sensitive Hashing scheme

===================================================================

This is a python 3 implementation of a locality sensitive hashing scheme

that makes use of the Goemans-Williamson SDP rounding technique for approximating

MAXCUT. A locality sensitive hashing scheme maps "close" strings to the same 

bucket. The notion of closeness depends on the way the data is mapped to

vectors (for instance the characteristic vector if it is a text, or the 

frequency vector). The Goemans-Williamson rounding technique samples a n-variate

Gaussian x (n being the dimension of the data) and rounds the data vector v to 1

if <v,x> >= 0 and to 0 otherwise. Here we map an n-bit vector to a log^2(n) bit vector

with the probability of collision being:

	(1-a/\pi)^{(log n)^2} 

where a is the angle between the two vectors. Note that if the machine precision is k

(typically a constant in n) then the probability of collision is atleast

	(1-1/(2^k*\pi))^{(log n)^2}

which is asymptotically inverse super-polynomial in n.

The generate-example.py generates a file (by default named data) with random vectors.

The hash.py uses this hashing scheme to hash it to a file of your choosing. It also 

outputs the number of collisions that were observed on the data where the number is 

defined to be the sum of (the number of vectors in the bucket-1) over all occupied buckets.

A sample data file is also included in the repository. 

Reference: http://www.cs.princeton.edu/courses/archive/spring04/cos598B/bib/CharikarEstim.pdf 
